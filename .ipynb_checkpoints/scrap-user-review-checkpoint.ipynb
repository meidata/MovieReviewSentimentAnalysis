{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class getReviewPerMovie(object):\n",
    "    def __init__(self,movieNumber):\n",
    "        self.site = 'http://www.imdb.com/title/'+str(movieNumber)+'/reviews'\n",
    "        \n",
    "    def getLength(self,type_re):\n",
    "        first_page = self.site +'?filter='+ type_re + ';filter='+ type_re +';start='+'0'\n",
    "        html_l = requests.get(first_page)\n",
    "        soup_l = BeautifulSoup(html_l.text,\"html.parser\")   \n",
    "        tbl = soup_l.findAll('table')[1]\n",
    "        row_n = tbl.find_all('tr')\n",
    "        str_len = row_n[0].find_all('td')[0].text\n",
    "        regex = r\"(Page).(\\d).(of).(\\d*)(.+)\"\n",
    "        len_review = re.sub(regex, '\\\\4',str_len)\n",
    "        return(len_review)\n",
    "    \n",
    "    def category(self,ca_re):\n",
    "        reviews = []\n",
    "        rev=[]\n",
    "        for i in range(0, int(self.getLength(str(ca_re)))):\n",
    "            link= self.site +'?filter='+ ca_re + ';filter='+ ca_re +';start='+ str(i*10)\n",
    "            print(link)\n",
    "            html_link = requests.get(link)\n",
    "            soup = BeautifulSoup(html_link.text,\"html.parser\")   \n",
    "            review_soup = soup.find(\"div\", {\"id\": \"tn15content\"})\n",
    "            \n",
    "            \n",
    "            for div_re in review_soup.find_all('div'):\n",
    "                user_info_dict = {}\n",
    "                for user_info in div_re.find_all('img',alt=True):\n",
    "                    user_info_dict['rating']=user_info.get('alt')\n",
    "                    user_info_dict['author']=re.sub(r\"(/user/)(ur\\d+)(/)\",'\\\\2',user_info.a.get('href'))\n",
    "                    user_info_dict['title']=div_re.h2.text\n",
    "                    if ca_re == 'love':\n",
    "                        user_info_dict['categorie']='postive'\n",
    "                    else:\n",
    "                        user_info_dict['categorie']='negative'\n",
    "                    if user_info.small is not None:\n",
    "                        reg = r\"(<small>)(\\d+)( out of )(\\d+)(.+)\"\n",
    "                        user_info_dict['usefulness'] = re.sub(reg,'\\\\2/\\\\4',str(div_re.small))\n",
    "                        reviews.append(user_info_dict)\n",
    "                        #print(user_info_dict)\n",
    "                        \n",
    "            for re_text in review_soup.find_all('p'):\n",
    "                review_text = {}\n",
    "                if re_text.getText() not in ['*** This review may contain spoilers ***',\n",
    "                                             'Add another review']:\n",
    "                    review_text['review'] =re_text.getText()\n",
    "                    rev.append(review_text)\n",
    "        \n",
    "        for i in range(0,len(reviews)):\n",
    "            if len(reviews) == len(rev):\n",
    "                reviews[i]['review'] = rev[i]['review']\n",
    "            else:\n",
    "                print('the length of the user info and review is not the same','...\\n',\n",
    "                     'user info has length: ',str(len(reviews)),'...\\n',\n",
    "                      'review has length: ',str(len(rev)),'...\\n')\n",
    "                \n",
    "        return reviews\n",
    "                   \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.imdb.com/title/tt2034800/reviews?filter=love;filter=love;start=0\n",
      "http://www.imdb.com/title/tt2034800/reviews?filter=love;filter=love;start=10\n",
      "http://www.imdb.com/title/tt2034800/reviews?filter=love;filter=love;start=20\n",
      "http://www.imdb.com/title/tt2034800/reviews?filter=love;filter=love;start=30\n",
      "http://www.imdb.com/title/tt2034800/reviews?filter=hate;filter=hate;start=0\n",
      "http://www.imdb.com/title/tt2034800/reviews?filter=hate;filter=hate;start=10\n",
      "http://www.imdb.com/title/tt2034800/reviews?filter=hate;filter=hate;start=20\n",
      "http://www.imdb.com/title/tt2034800/reviews?filter=hate;filter=hate;start=30\n"
     ]
    }
   ],
   "source": [
    "pos = getReviewPerMovie('tt2034800').category('love')\n",
    "neg = getReviewPerMovie('tt2034800').category('hate')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
