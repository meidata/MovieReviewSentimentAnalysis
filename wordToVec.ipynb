{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re \n",
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup \n",
    "import matplotlib.pyplot as plt\n",
    "pd.set_option(\"display.max_colwidth\",-1)\n",
    "\n",
    "\n",
    "def rescue_code(function):\n",
    "    import inspect\n",
    "    get_ipython().set_next_input(\"\".join(inspect.getsourcelines(function)[0]))\n",
    "    \n",
    "\n",
    "    \n",
    "def tic():\n",
    "    #Homemade version of matlab tic and toc functions\n",
    "    import time\n",
    "    global startTime_for_tictoc\n",
    "    startTime_for_tictoc = time.time()\n",
    "\n",
    "def toc():\n",
    "    import time\n",
    "    if 'startTime_for_tictoc' in globals():\n",
    "        print(\"Elapsed time is \" + str(time.time() - startTime_for_tictoc) + \" seconds.\")\n",
    "    else:\n",
    "        print(\"Toc: start time not set\")\n",
    "        \n",
    "        \n",
    "        \n",
    "with open('drama_love_reviews_100.json') as json_data:\n",
    "    posReviewsDrama = json.load(json_data)\n",
    "    \n",
    "with open('drama_hate_reviews_100.json') as json_data:\n",
    "    negReviewsDrama = json.load(json_data)\n",
    "    \n",
    "with open('action_love_reviews_100.json') as json_data:\n",
    "    posReviewsAction = json.load(json_data)\n",
    "    \n",
    "with open('action_hate_reviews_100.json') as json_data:\n",
    "    negReviewsAction  = json.load(json_data)\n",
    "    \n",
    "with open('horror_hate_reviews_100.json') as json_data:\n",
    "    negReviewsHorror  = json.load(json_data) \n",
    "    \n",
    "with open('horror_love_reviews_100.json') as json_data:\n",
    "    posReviewsHorror  = json.load(json_data) \n",
    "    \n",
    "with open('romance_hate_reviews_100.json') as json_data:\n",
    "    negReviewsRomance  = json.load(json_data)     \n",
    "    \n",
    "with open('romance_love_reviews_100.json') as json_data:\n",
    "    posReviewsRomance  = json.load(json_data) \n",
    "    \n",
    "with open('Sci-Fi_love_reviews_100.json') as json_data:\n",
    "    posReviewsSci  = json.load(json_data) \n",
    "    \n",
    "with open('Sci-Fi_hate_reviews_100.json') as json_data:\n",
    "    negReviewsSci  = json.load(json_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "posReList = []\n",
    "for reviewlist in posReviewsDrama + posReviewsHorror + posReviewsAction + posReviewsSci + posReviewsRomance:\n",
    "    if reviewlist is not None:\n",
    "        for review in reviewlist:\n",
    "            posReList.append([review['review'],review['categorie']])\n",
    "            \n",
    "posReviews = pd.DataFrame(posReList,columns=['reviews', 'sentiment'])\n",
    "posReviews = posReviews.drop_duplicates()\n",
    "\n",
    "negReList = []\n",
    "for reviewlist in  negReviewsAction + negReviewsHorror +negReviewsDrama +negReviewsRomance + negReviewsSci:\n",
    "    if reviewlist is not None:\n",
    "        for review in reviewlist:\n",
    "            negReList.append([review['review'],review['categorie']])\n",
    "            \n",
    "negReviews = pd.DataFrame(negReList,columns=['reviews', 'sentiment'])\n",
    "negReviews = negReviews.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34079, 3)\n",
      "(14606, 3)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pos_train, pos_test = train_test_split(posReviews, test_size = 0.3)\n",
    "neg_train, neg_test = train_test_split(negReviews, test_size = 0.3)\n",
    "\n",
    "train = pos_train.append(neg_train, ignore_index=True)\n",
    "test = pos_test.append(neg_test, ignore_index=True)\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "train['id'] = train.index\n",
    "\n",
    "\n",
    "test = test.reset_index(drop=True)\n",
    "test['id'] = test.index\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train['reviews'] = train['reviews'].apply(lambda x : x.lower())\n",
    "#test['reviews'] = test['reviews'].apply(lambda x : x.lower())\n",
    "#re.sub(\"[^a-zA-Z]\",' ',train.ix[0,'reviews'])\n",
    "\n",
    "def textPrepocess(movieReviews):\n",
    "    movieReviews = movieReviews.lower()\n",
    "    movieReviews = re.sub(\"[^a-zA-Z]\",' ',movieReviews)\n",
    "    movieReviews = (\" \".join(movieReviews.split()))\n",
    "    return movieReviews\n",
    "\n",
    "train['reviews'] = train['reviews'].apply(textPrepocess)\n",
    "test['reviews'] = test['reviews'].apply(textPrepocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word2vec\n",
    "Word2vec is a **neural network implementation** that learns **distributed representations** for words. Other deep or recurrent neural network architectures had been proposed for learning word representations prior to this, but the major problem with these was the long time required to train the models. Word2vec learns quickly relative to other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Titles :             no titles\n",
    "2. Features Extraction: CountVectorizer()\n",
    "3. Stopwords :          Not remove\n",
    "4. Classifier :         Randomforest\n",
    "5. N-gram:              (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 936.9531109333038 seconds.\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    postive       0.80      0.69      0.74      6860\n",
      "   negative       0.75      0.85      0.80      7746\n",
      "\n",
      "avg / total       0.78      0.77      0.77     14606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(analyzer = \"word\" ,min_df=1)\n",
    "train_features = vectorizer.fit_transform(train['reviews'])\n",
    "train_features = train_features.toarray()\n",
    "vocabulary = vectorizer.get_feature_names()\n",
    "\n",
    "tic()\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest_100 = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "test_features = vectorizer.transform(test['reviews'])\n",
    "test_features = test_features.toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest_100 = forest_100.fit(train_features, train[\"sentiment\"])\n",
    "result = forest_100.predict(test_features)\n",
    "toc()\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "target_names = ['postive', 'negative']\n",
    "print(classification_report(test['sentiment'], result, target_names=target_names))\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
