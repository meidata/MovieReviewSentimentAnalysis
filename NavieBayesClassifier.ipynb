{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size.. (34092, 3) ..\n",
      "\n",
      "test data size.. (14613, 3) ..\n",
      "\n",
      "all data has been imported..\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import csv\n",
    "import json\n",
    "import nltk\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from bs4 import BeautifulSoup \n",
    "import matplotlib.pyplot as plt\n",
    "from reviewsData import * \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "pd.set_option(\"display.max_colwidth\",-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf_vectorizer = TfidfVectorizer(analyzer='word',ngram_range=(1,2))\n",
    "        \n",
    "train_features_tf = tf_vectorizer.fit_transform(test)\n",
    "tf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import metrics\n",
    "\n",
    "# Generate counts from text using a vectorizer.  There are other vectorizers available, and lots of options you can set.\n",
    "# This performs our step of computing word counts.\n",
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "train_features = vectorizer.fit_transform([r[0] for r in reviews])\n",
    "test_features = vectorizer.transform([r[0] for r in test])\n",
    "\n",
    "# Fit a naive bayes model to the training data.\n",
    "# This will train the model using the word counts we computer, and the existing classifications in the training set.\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_features, [int(r[1]) for r in reviews])\n",
    "\n",
    "# Now we can use the model to predict classifications for our test features.\n",
    "predictions = nb.predict(test_features)\n",
    "\n",
    "# Compute the error.  It is slightly different from our model because the internals of this process work differently from our implementation.\n",
    "fpr, tpr, thresholds = metrics.roc_curve(actual, predictions, pos_label=1)\n",
    "print(\"Multinomial naive bayes AUC: {0}\".format(metrics.auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.metrics import classification_report,roc_curve\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "            \n",
    "def NaiveBayesclassifier(min_gram,max_gram,df_train,df_test,is_stopWords):\n",
    "    tic()\n",
    "    target_names = ['postive', 'negative']\n",
    "    \n",
    "    if is_stopWords == True:\n",
    "        tf_vectorizer = TfidfVectorizer(min_df= 3, \n",
    "                                        max_df = 0.9,\n",
    "                                        sublinear_tf=True,\n",
    "                                        use_idf=True,\n",
    "                                        ngram_range=(min_gram,max_gram),\n",
    "                                        stop_words = 'english')\n",
    "        \n",
    "    elif is_stopWords == False:\n",
    "        tf_vectorizer = TfidfVectorizer(min_df=5, \n",
    "                                        max_df = 0.8,\n",
    "                                        sublinear_tf=True,\n",
    "                                        use_idf=True,\n",
    "                                        ngram_range=(min_gram,max_gram),\n",
    "                                        stop_words = None)\n",
    "\n",
    "   \n",
    "    train_vectors = tf_vectorizer.fit_transform(df_train['reviews'])\n",
    "    test_vectors = tf_vectorizer.transform(df_test['reviews'])\n",
    "    toc()\n",
    "    \n",
    "    \n",
    "\n",
    "    tic()\n",
    "    print('Training classifier...\\n')\n",
    "    classifier = MultinomialNB()\n",
    "    classifier.fit(train_vectors, df_train['sentiment'])\n",
    "    prediction = classifier.predict(test_vectors)\n",
    "    toc()\n",
    "    \n",
    "    print('Classifier: Naive Bayes, ','n-gram: ',min_gram,max_gram,'..\\n')\n",
    "    \n",
    "    print('Accuracy score = ',accuracy_score(df_test['sentiment'], prediction),'..\\n')\n",
    "    \n",
    "    print(classification_report(df_test['sentiment'], prediction, target_names=target_names))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 10.341602087020874 seconds..\n",
      "\n",
      "Training classifier...\n",
      "\n",
      "Elapsed time is 0.20534992218017578 seconds..\n",
      "\n",
      "Classifier: Naive Bayes,  n-gram:  1 1 ..\n",
      "\n",
      "Accuracy score =  0.813043180729 ..\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    postive       0.86      0.72      0.78      6862\n",
      "   negative       0.78      0.89      0.84      7751\n",
      "\n",
      "avg / total       0.82      0.81      0.81     14613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayesclassifier(1,1,train,test,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 10.047274827957153 seconds..\n",
      "\n",
      "Training classifier...\n",
      "\n",
      "Elapsed time is 0.2073218822479248 seconds..\n",
      "\n",
      "Classifier: Naive Bayes,  n-gram:  1 1 ..\n",
      "\n",
      "Accuracy score =  0.809484705399 ..\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    postive       0.85      0.72      0.78      6862\n",
      "   negative       0.78      0.89      0.83      7751\n",
      "\n",
      "avg / total       0.81      0.81      0.81     14613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayesclassifier(1,1,train,test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 33.07360601425171 seconds..\n",
      "\n",
      "Training classifier...\n",
      "\n",
      "Elapsed time is 0.2507190704345703 seconds..\n",
      "\n",
      "Classifier: Naive Bayes,  n-gram:  1 2 ..\n",
      "\n",
      "Accuracy score =  0.819612673647 ..\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    postive       0.87      0.73      0.79      6862\n",
      "   negative       0.79      0.90      0.84      7751\n",
      "\n",
      "avg / total       0.83      0.82      0.82     14613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayesclassifier(1,2,train,test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 42.48508310317993 seconds..\n",
      "\n",
      "Training classifier...\n",
      "\n",
      "Elapsed time is 0.35024380683898926 seconds..\n",
      "\n",
      "Classifier: Naive Bayes,  n-gram:  1 2 ..\n",
      "\n",
      "Accuracy score =  0.826866488743 ..\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    postive       0.90      0.71      0.79      6862\n",
      "   negative       0.78      0.93      0.85      7751\n",
      "\n",
      "avg / total       0.84      0.83      0.82     14613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayesclassifier(1,2,train,test,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 100.84147095680237 seconds..\n",
      "\n",
      "Training classifier...\n",
      "\n",
      "Elapsed time is 0.5554389953613281 seconds..\n",
      "\n",
      "Classifier: Naive Bayes,  n-gram:  1 3 ..\n",
      "\n",
      "Accuracy score =  0.826455895436 ..\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    postive       0.91      0.70      0.79      6862\n",
      "   negative       0.78      0.94      0.85      7751\n",
      "\n",
      "avg / total       0.84      0.83      0.82     14613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayesclassifier(1,3,train,test,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 62.70658898353577 seconds..\n",
      "\n",
      "Training classifier...\n",
      "\n",
      "Elapsed time is 0.2563488483428955 seconds..\n",
      "\n",
      "Classifier: Naive Bayes,  n-gram:  1 3 ..\n",
      "\n",
      "Accuracy score =  0.820023266954 ..\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    postive       0.86      0.74      0.79      6862\n",
      "   negative       0.79      0.90      0.84      7751\n",
      "\n",
      "avg / total       0.82      0.82      0.82     14613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayesclassifier(1,3,train,test,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 11.359928846359253 seconds..\n",
      "\n",
      "Training classifier...\n",
      "\n",
      "Elapsed time is 0.21829819679260254 seconds..\n",
      "\n",
      "Classifier: Naive Bayes,  n-gram:  1 1 ..\n",
      "\n",
      "Accuracy score =  0.813043180729 ..\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    postive       0.86      0.72      0.78      6862\n",
      "   negative       0.78      0.89      0.84      7751\n",
      "\n",
      "avg / total       0.82      0.81      0.81     14613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#min_df= 3, max_df = 0.9\n",
    "\n",
    "NaiveBayesclassifier(1,1,train,test,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 44.92691898345947 seconds..\n",
      "\n",
      "Training classifier...\n",
      "\n",
      "Elapsed time is 0.39043402671813965 seconds..\n",
      "\n",
      "Classifier: Naive Bayes,  n-gram:  1 2 ..\n",
      "\n",
      "Accuracy score =  0.826866488743 ..\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    postive       0.90      0.71      0.79      6862\n",
      "   negative       0.78      0.93      0.85      7751\n",
      "\n",
      "avg / total       0.84      0.83      0.82     14613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#min_df= 3, max_df = 0.9\n",
    "\n",
    "NaiveBayesclassifier(1,2,train,test,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 106.69622087478638 seconds..\n",
      "\n",
      "Training classifier...\n",
      "\n",
      "Elapsed time is 0.4719829559326172 seconds..\n",
      "\n",
      "Classifier: Naive Bayes,  n-gram:  1 3 ..\n",
      "\n",
      "Accuracy score =  0.826455895436 ..\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    postive       0.91      0.70      0.79      6862\n",
      "   negative       0.78      0.94      0.85      7751\n",
      "\n",
      "avg / total       0.84      0.83      0.82     14613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#min_df= 3, max_df = 0.9\n",
    "\n",
    "NaiveBayesclassifier(1,3,train,test,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 190.22675204277039 seconds..\n",
      "\n",
      "Training classifier...\n",
      "\n",
      "Elapsed time is 0.529339075088501 seconds..\n",
      "\n",
      "Classifier: Naive Bayes,  n-gram:  1 4 ..\n",
      "\n",
      "Accuracy score =  0.827482378704 ..\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    postive       0.90      0.71      0.79      6862\n",
      "   negative       0.78      0.93      0.85      7751\n",
      "\n",
      "avg / total       0.84      0.83      0.82     14613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NaiveBayesclassifier(1,4,train,test,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
